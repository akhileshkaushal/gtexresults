{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASH analysis for Urbut 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the \"master\" analysis for Urbut et al 2017, using [`mashr-paper`](https://github.com/stephenslab/mashr-paper) version of MASH implementation.\n",
    "\n",
    "**FIXME: add more intro here**:\n",
    "\n",
    "1. Explain the input / output -- make it clear that we've omitted the steps tha converts summary stats from gtex portal to mashable format, and that we did not apply the inference to all the gene-snp pairs.\n",
    "2. Explain that we have refactored to code to `mashr` repo. We may or may not want to point to [the analysis that uses the new `mashr` code](http://stephenslab.github.io/gtex-eqtls/analysis/20171002_MASH_V8.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some note to the code corresponding to the core analysis:\n",
    "    \n",
    "    1. `ms=deconvolution.em.with.bovy(t.stat,factor.mat,v.j,lambda.mat,K=3,P=3)`\n",
    "\n",
    "produces an object with the denoised matrices for feeding into the\n",
    "*mash* covariance code. The *factor.mat* and *lambda.mat* called\n",
    "within have been produced by SFA and are single rank factors and\n",
    "loadings approximating the empirical covariance.\n",
    "\n",
    "    2. `covmat=compute.hm.covmat.all.max.step(b.hat=z.stat,se.hat=v.j,t.stat=z.stat,Q=5,lambda.mat,A=A,factor.mat,max.step=max.step,zero=TRUE)$covmat` \n",
    "\n",
    "produces a list of covariance matrices entitled *covmat\"A\".rds* upon\n",
    "which to base the mixture of multivariate normals.\n",
    "\n",
    "    3. `compute.hm.train.log.lik(train.b = train.z,se.train = train.v,covmat = covmat,A,pen=TRUE)`\n",
    "\n",
    "computes the HM weights on training datauses the set of randomly chosen genes to train our model and produces\n",
    "a matrix of likelihoods and corresponding hierarchical weights, as well as the mixture proportions.\n",
    "\n",
    "    4. `weightedquants=lapply(seq(1:nrow(z.stat)),function(j){total.quant.per.snp(j,covmat,b.gp.hat=z.stat,se.gp.hat = v.j,pis,A,checkpoint = FALSE)})`\n",
    "\n",
    "produces files containing the posterior means, upper and lower\n",
    "tail probabilities, null probabilites, and lfsr for all J genes across\n",
    "44 conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = '~/Documents/GTEx/mash_analysis'\n",
    "sfa_exe = \"${cwd!a}/sfa/bin/sfa_linux\"\n",
    "mashr_src = \"${cwd!a}/mashr-paper-0.2-1/R/main.R\"\n",
    "parameter: data = \"data/MatrixEQTLSumStats.Portable.Z.rds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance pattern discovery\n",
    "This obtains covariance matrices, ie, the priors, for `mash` model.\n",
    "\n",
    "### SFA\n",
    "We analyze data with SFA. The cell below downloads SFA software and run it on data with rank `K = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%sosrun sfa\n",
    "[sfa_download: provides = sfa_exe]\n",
    "task: workdir = cwd\n",
    "download: decompress = True\n",
    "    http://stephenslab.uchicago.edu/assets/software/sfa/sfa1.0.tar.gz\n",
    "\n",
    "[sfa]\n",
    "depends: sfa_exe\n",
    "K = 5\n",
    "tmpfile = \"/tmp/${data!bn}.max.txt\"\n",
    "input: data\n",
    "output: \"${input!n}.sfa.rds\"\n",
    "task: workdir = cwd\n",
    "R:\n",
    "    z = readRDS(${input!ar})$test.z\n",
    "    write.table(z, ${tmpfile!r}, col.names=F,row.names=F)\n",
    "    cmd = paste0('${sfa_exe} -gen ${tmpfile} -g ', dim(z)[1], ' -n ', dim(z)[2], \n",
    "                 ' -k ${K} -iter 50 -rand 999 -o ${input!bn}')\n",
    "    system(cmd)\n",
    "    saveRDS(list(F = read.table(\"${input!n}_F.out\"),\n",
    "                lambda = read.table(\"${input!n}_lambda.out\"),\n",
    "                sigma2 = read.table(\"${input!n}_sigma2.out\"),\n",
    "                alpha = read.table(\"${input!n}_alpha.out\")), ${output!r})\n",
    "bash:\n",
    "    rm -f *{_F.out,_lambda.out,_sigma2.out,_alpha.out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create and refine multi-rank covariance matrices\n",
    "Here we create 3 covariance matrices:\n",
    "\n",
    "* SFA (rank 5, previously computed)\n",
    "* SVD (rank 3, to be computed)\n",
    "* Empirical covariance\n",
    "\n",
    "and apply [Extreme Deconvolution](https://github.com/jobovy/extreme-deconvolution) to refine the matrices. We observed that Extreme Deconvolution perserves rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mashr_download: provides = mashr_src]\n",
    "task: workdir = cwd\n",
    "download: decompress = True\n",
    "    https://github.com/stephenslab/mashr-paper/archive/v0.2-1.zip\n",
    "\n",
    "[mash_1]\n",
    "# Perform SVD + ED\n",
    "depends: R_library(\"ExtremeDeconvolution\"), mashr_src\n",
    "K = 3\n",
    "P = 3\n",
    "input: data, \"${data!n}.sfa.rds\"\n",
    "output: \"${data!n}.coved.${K}.${P}.rds\"\n",
    "task: workdir = cwd\n",
    "R:\n",
    "    setwd(\"${mashr_src!da}\")\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd!ar})\n",
    "    dat = readRDS('${data}')\n",
    "    t.stat = dat$test.z\n",
    "    mean.mat = matrix(rep(0,ncol(t.stat)*nrow(t.stat)),ncol=ncol(t.stat),nrow=nrow(t.stat))\n",
    "    s.j = matrix(rep(1,ncol(t.stat)*nrow(t.stat)),ncol=ncol(t.stat),nrow=nrow(t.stat))\n",
    "    v.mat = dat$vhat\n",
    "    v.j=list()\n",
    "    for(i in 1:nrow(t.stat)){v.j[[i]]=v.mat}\n",
    "    K = ${K}\n",
    "    P = ${P}\n",
    "    R = ncol(t.stat)\n",
    "    sfa = readRDS(\"${data!n}.sfa.rds\")\n",
    "    init.cov = init.covmat(t.stat=t.stat, factor.mat = as.matrix(sfa$F),lambda.mat = as.matrix(sfa$lambda), K=K,P=P)\n",
    "    init.cov.list = list()\n",
    "    for(i in 1:K){init.cov.list[[i]]=init.cov[i,,]}\n",
    "    projection = list();for(l in 1:nrow(t.stat)){projection[[l]]=diag(1,R)}\n",
    "    e = ExtremeDeconvolution::extreme_deconvolution(ydata=t.stat,ycovar=v.j,xamp=rep(1/K,K),xmean=mean.mat,xcovar=init.cov.list,fixmean=T,projection=projection)\n",
    "    true.covs = array(dim=c(K,R,R))\n",
    "    for(i in 1:K){true.covs[i,,]=e$xcovar[[i]]}\n",
    "    saveRDS(list(true.covs=true.covs,pi=e$xamp), ${output!r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add in single-rank covariance matrices\n",
    "Now additionally we include 2 other types of covariance matrices:\n",
    "* canonical configurations (aka `bmalite`)\n",
    "* single rank SFA\n",
    "\n",
    "We also expand the list of matrices by grid. At the end of this step (cell below) we are ready to fit the mash model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_2: shared = {'prior_matrices': 'output'}]\n",
    "output: \"${input!n}.lite.single.expanded.rds\"\n",
    "task: workdir = cwd\n",
    "R:\n",
    "    setwd(\"${mashr_src!da}\")\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd!ar})\n",
    "    dat = readRDS('${data}')\n",
    "    z.stat = dat$test.z\n",
    "    rownames(z.stat) = NULL\n",
    "    colnames(z.stat) = NULL\n",
    "    v.mat = dat$vhat\n",
    "    s.j = matrix(rep(1,ncol(z.stat)*nrow(z.stat)),ncol=ncol(z.stat),nrow=nrow(z.stat))\n",
    "    sfa = readRDS(\"${data!n}.sfa.rds\")\n",
    "    res = compute.hm.covmat.all.max.step(b.hat=z.stat,se.hat=s.j,\n",
    "                                          t.stat=z.stat,Q=5,\n",
    "                                          lambda.mat=as.matrix(sfa$lambda),\n",
    "                                          A='.remove_before_rerun',factor.mat=as.matrix(sfa$F),\n",
    "                                          max.step=readRDS(${input!r}),\n",
    "                                          zero=TRUE)\n",
    "    saveRDS(res, ${output!r})\n",
    "\n",
    "run:\n",
    "    rm -f *.remove_before_rerun.rds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit MASH mixture model\n",
    "Using a training set, the cell below computes the weights for input covariance matrices (priors) in MASH mixture. The output contains matrix of log-likelihoods as well as weights learned from the hierarchical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_3]\n",
    "depends: R_library(\"SQUAREM\")\n",
    "output: \"${input!n}.pihat.rds\", \"${input!n}.loglik.rds\"\n",
    "task: workdir = cwd\n",
    "R:\n",
    "    library(\"SQUAREM\")\n",
    "    setwd(\"${mashr_src!da}\")\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd!ar})\n",
    "    dat = readRDS('${data}')\n",
    "    v.mat = dat$vhat\n",
    "    covmat = readRDS(${input!r})$covmat\n",
    "    train.z=as.matrix(dat$train.z)\n",
    "    rownames(train.z)=NULL\n",
    "    colnames(train.z)=NULL\n",
    "    train.v=train.z/train.z\n",
    "    res = compute.hm.train.log.lik.pen.vmat(train.b = train.z,\n",
    "                                            covmat = covmat,\n",
    "                                            A = '.remove_before_rerun', \n",
    "                                            pen = 1,\n",
    "                                            train.s = train.v,\n",
    "                                            cormat = v.mat)\n",
    "    saveRDS(res$pis, ${output[0]!r})\n",
    "    saveRDS(res$lik.mat, ${output[1]!r})\n",
    "\n",
    "run:\n",
    "    rm -f *.remove_before_rerun.rds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior inference\n",
    "Applying hyperparameters learned from the training set to the test set, the cell below computes posterior quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_4]\n",
    "depends: sos_variable('prior_matrices')\n",
    "output: \"${input[0]!nn}.posterior.rds\"\n",
    "task: workdir = cwd\n",
    "R:\n",
    "    setwd(\"${mashr_src!da}\")\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd!ar})\n",
    "    dat = readRDS(${data!r})\n",
    "    z.stat = dat$test.z\n",
    "    v.mat = dat$vhat\n",
    "    s.j=matrix(rep(1,ncol(z.stat)*nrow(z.stat)),ncol=ncol(z.stat),nrow=nrow(z.stat))\n",
    "    pis = readRDS(${input[0]!r})$pihat\n",
    "    covmat = readRDS(${prior_matrices!r})$covmat\n",
    "    res = lapply(seq(1:nrow(z.stat)), function(j){\n",
    "        total.quant.per.snp.with.vmat(j=j, covmat=covmat, \n",
    "                                      b.gp.hat=z.stat, \n",
    "                                      cormat=v.mat, \n",
    "                                      se.gp.hat=s.j, \n",
    "                                      pis=pis, \n",
    "                                      A='remove_before_rerun', \n",
    "                                      checkpoint = TRUE)})\n",
    "    # data formatting.\n",
    "    out = do.call(Map, c(f = rbind, res))\n",
    "    saveRDS(out, ${output!r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now MASH analysis is complete. I will use a separate notebook to summarize, plot and visualize the result of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this notebook\n",
    "For repeated runs it might be easier to execute from commandline instead of in Jupyter:\n",
    "\n",
    "```bash\n",
    "sos run code/master_mash_analysis.ipynb sfa # --data\n",
    "sos run code/master_mash_analysis.ipynb mash # --data ... --cwd ...\n",
    "```\n",
    "\n",
    "The notebook runs default setting. Additionally I run it for dataset after LD pruning (for LD related discussion in supplemental information):\n",
    "\n",
    "```bash\n",
    "sos run code/master_mash_analysis.ipynb sfa \\\n",
    "    --data data/MatrixEQTLSumStats.Portable.ld2.Z.rds\n",
    "sos run code/master_mash_analysis.ipynb mash \\\n",
    "    --data data/MatrixEQTLSumStats.Portable.ld2.Z.rds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p class=\"session_section\">SoS</p>\n",
       "<table class=\"session_info\">\n",
       "<tr>\n",
       "<th>SoS Version</th><td><pre>0.9.8.10</pre></td>\n",
       "</tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sessioninfo"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
