{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASH analysis of GTEx data, Urbut 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the \"master\" analysis for Urbut et al 2017, using [`mashr-paper`](https://github.com/stephenslab/mashr-paper) version of MASH implementation.\n",
    "\n",
    "**FIXME: add more intro here**:\n",
    "\n",
    "1. Explain the input / output -- make it clear that we've omitted the steps tha converts summary stats from gtex portal to mashable format, and that we did not apply the inference to all the gene-snp pairs.\n",
    "2. Explain that we have refactored to code to `mashr` repo. We may or may not want to point to [the analysis that uses the new `mashr` code](http://stephenslab.github.io/gtex-eqtls/analysis/20171002_MASH_V8.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this notebook\n",
    "For repeated runs it might be easier to execute from commandline instead of in Jupyter:\n",
    "\n",
    "```bash\n",
    "sos run code/master_mash_analysis.ipynb # --data ... --cwd ...\n",
    "```\n",
    "\n",
    "The notebook runs default setting. Additionally I run it for dataset after LD pruning (for LD related discussion in supplemental information):\n",
    "\n",
    "```bash\n",
    "sos run code/master_mash_analysis.ipynb --data data/MatrixEQTLSumStats.Portable.ld2.Z.rds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about the code used for the core analysis:\n",
    "    \n",
    "    1. `ms=deconvolution.em.with.bovy(t.stat,factor.mat,v.j,lambda.mat,K=3,P=3)`\n",
    "\n",
    "produces an object with the denoised matrices for feeding into the\n",
    "*mash* covariance code. The *factor.mat* and *lambda.mat* called\n",
    "within have been produced by SFA and are single rank factors and\n",
    "loadings approximating the empirical covariance.\n",
    "\n",
    "    2. `covmat=compute.hm.covmat.all.max.step(b.hat=z.stat,se.hat=v.j,t.stat=z.stat,Q=5,lambda.mat,A=A,factor.mat,max.step=max.step,zero=TRUE)$covmat` \n",
    "\n",
    "produces a list of covariance matrices entitled *covmat\"A\".rds* upon\n",
    "which to base the mixture of multivariate normals.\n",
    "\n",
    "    3. `compute.hm.train.log.lik(train.b = train.z,se.train = train.v,covmat = covmat,A,pen=TRUE)`\n",
    "\n",
    "computes the HM weights on training datauses the set of randomly chosen genes to train our model and produces\n",
    "a matrix of likelihoods and corresponding hierarchical weights, as well as the mixture proportions.\n",
    "\n",
    "    4. `weightedquants=lapply(seq(1:nrow(z.stat)),function(j){total.quant.per.snp(j,covmat,b.gp.hat=z.stat,se.gp.hat = v.j,pis,A,checkpoint = FALSE)})`\n",
    "\n",
    "produces files containing the posterior means, upper and lower\n",
    "tail probabilities, null probabilites, and lfsr for all J genes across\n",
    "44 conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path('./gtex6_workflow_output')\n",
    "parameter: data = path(\"data/MatrixEQTLSumStats.Portable.Z.rds\")\n",
    "# path configured to use with root privilege, for `docker` \n",
    "mashr_src = path(\"/opt/mash-paper/main.R\")\n",
    "sfa_exe = \"/opt/sfa/bin/sfa_linux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance pattern discovery\n",
    "This obtains covariance matrices, ie, the priors, for `mash` model.\n",
    "\n",
    "### SFA\n",
    "We analyze data with SFA. The cell below downloads SFA software and run it on data with rank `K = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%sosrun sfa\n",
    "[sfa_download: provides = sfa_exe]\n",
    "download: decompress = True, dest_dir = cwd\n",
    "    http://stephenslab.uchicago.edu/assets/software/sfa/sfa1.0.tar.gz\n",
    "\n",
    "[sfa]\n",
    "# Perform SFA analysis (time estimate: ~3min)\n",
    "depends: sfa_exe\n",
    "K = 5\n",
    "tmpfile = path(f\"{cwd:a}/{data:bn}.max.txt\")\n",
    "input: f\"{data:a}\"\n",
    "output: f\"{cwd:a}/{_input:bn}.sfa.rds\"\n",
    "R: expand = \"${ }\", stdout = f\"{_output}.log\", workdir = cwd\n",
    "    z = readRDS(${_input:r})$test.z\n",
    "    write.table(z, ${tmpfile:r}, col.names=F,row.names=F)\n",
    "    cmd = paste0('${sfa_exe} -gen ${tmpfile} -g ', dim(z)[1], ' -n ', dim(z)[2], \n",
    "                 ' -k ${K} -iter 50 -rand 999 -o ${_output:bn}')\n",
    "    system(cmd)\n",
    "    saveRDS(list(F = read.table(\"${_output:n}_F.out\"),\n",
    "                lambda = read.table(\"${_output:n}_lambda.out\"),\n",
    "                sigma2 = read.table(\"${_output:n}_sigma2.out\"),\n",
    "                alpha = read.table(\"${_output:n}_alpha.out\")), ${_output:r})\n",
    "bash: workdir = cwd\n",
    "    rm -f *{_F.out,_lambda.out,_sigma2.out,_alpha.out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create and refine multi-rank covariance matrices\n",
    "Here we create 3 covariance matrices:\n",
    "\n",
    "* SFA (rank 5, previously computed)\n",
    "* SVD (rank 3, to be computed)\n",
    "* Empirical covariance\n",
    "\n",
    "and apply [Extreme Deconvolution](https://github.com/jobovy/extreme-deconvolution) to refine the matrices. We observed that Extreme Deconvolution perserves rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mashr_download: provides = mashr_src]\n",
    "task: workdir = cwd\n",
    "download: decompress = True\n",
    "    https://github.com/stephenslab/mashr-paper/archive/v0.2-1.zip\n",
    "\n",
    "[mash_1: shared = {'mash_input': '_input'}]\n",
    "# Compute data-driven prior matrices (time estimate: ~1.5hr)\n",
    "depends: R_library(\"ExtremeDeconvolution\"), mashr_src\n",
    "K = 3\n",
    "P = 3\n",
    "input: f\"{data:a}\", f\"{cwd:a}/{data:bn}.sfa.rds\"\n",
    "output: f\"{cwd:a}/{data:bn}.coved.K{K}.P{P}.rds\"\n",
    "R: expand = \"${ }\", workdir = cwd\n",
    "    setwd(${mashr_src:dar})\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd:ar})\n",
    "    dat = readRDS(${_input[0]:r})\n",
    "    t.stat = dat$test.z\n",
    "    mean.mat = matrix(rep(0,ncol(t.stat)*nrow(t.stat)),ncol=ncol(t.stat),nrow=nrow(t.stat))\n",
    "    s.j = matrix(rep(1,ncol(t.stat)*nrow(t.stat)),ncol=ncol(t.stat),nrow=nrow(t.stat))\n",
    "    v.mat = dat$vhat\n",
    "    v.j=list()\n",
    "    for(i in 1:nrow(t.stat)){v.j[[i]]=v.mat}\n",
    "    K = ${K}\n",
    "    P = ${P}\n",
    "    R = ncol(t.stat)\n",
    "    sfa = readRDS(${_input[1]:r})\n",
    "    init.cov = init.covmat(t.stat=t.stat, factor.mat = as.matrix(sfa$F),lambda.mat = as.matrix(sfa$lambda), K=K,P=P)\n",
    "    init.cov.list = list()\n",
    "    for(i in 1:K){init.cov.list[[i]]=init.cov[i,,]}\n",
    "    projection = list();for(l in 1:nrow(t.stat)){projection[[l]]=diag(1,R)}\n",
    "    e = ExtremeDeconvolution::extreme_deconvolution(ydata=t.stat,ycovar=v.j,xamp=rep(1/K,K),xmean=mean.mat,xcovar=init.cov.list,fixmean=T,projection=projection)\n",
    "    true.covs = array(dim=c(K,R,R))\n",
    "    for(i in 1:K){true.covs[i,,]=e$xcovar[[i]]}\n",
    "    saveRDS(list(true.covs=true.covs,pi=e$xamp), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add in single-rank covariance matrices\n",
    "Now additionally we include 2 other types of covariance matrices:\n",
    "* canonical configurations (aka `bmalite`)\n",
    "* single rank SFA\n",
    "\n",
    "We also expand the list of matrices by grid. At the end of this step (cell below) we are ready to fit the mash model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_2: shared = {'prior_matrices': '_output'}]\n",
    "# Add in canonical configurations and single rank SFA priors (time estimate: <1min)\n",
    "depends: sos_variable('mash_input')\n",
    "output: f\"{_input:n}.lite.single.expanded.rds\"\n",
    "R: expand = \"${ }\", workdir = cwd\n",
    "    setwd(${mashr_src:dar})\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd:ar})\n",
    "    dat = readRDS(${mash_input[0]:r})\n",
    "    z.stat = dat$test.z\n",
    "    rownames(z.stat) = NULL\n",
    "    colnames(z.stat) = NULL\n",
    "    v.mat = dat$vhat\n",
    "    s.j = matrix(rep(1,ncol(z.stat)*nrow(z.stat)),ncol=ncol(z.stat),nrow=nrow(z.stat))\n",
    "    sfa = readRDS(${mash_input[1]:r})\n",
    "    res = compute.hm.covmat.all.max.step(b.hat=z.stat,se.hat=s.j,\n",
    "                                          t.stat=z.stat,Q=5,\n",
    "                                          lambda.mat=as.matrix(sfa$lambda),\n",
    "                                          A='.remove_before_rerun',\n",
    "                                          factor.mat=as.matrix(sfa$F),\n",
    "                                          max.step=readRDS(${_input:r}),\n",
    "                                          zero=TRUE)\n",
    "    saveRDS(res, ${_output:r})\n",
    "\n",
    "bash: workdir = cwd\n",
    "    rm -f *.remove_before_rerun.rds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit MASH mixture model\n",
    "Using a training set, the cell below computes the weights for input covariance matrices (priors) in MASH mixture. The output contains matrix of log-likelihoods as well as weights learned from the hierarchical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_3]\n",
    "# Fit MASH mixture model (time estimate: )\n",
    "depends: R_library(\"SQUAREM\")\n",
    "output: f\"{_input:n}.pihat.rds\", f\"{_input:n}.loglik.rds\"\n",
    "R: expand = \"${ }\", workdir = cwd\n",
    "    library(\"SQUAREM\")\n",
    "    setwd(${mashr_src:dar})\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd:ar})\n",
    "    dat = readRDS(${mash_input[0]:r})\n",
    "    v.mat = dat$vhat\n",
    "    covmat = readRDS(${_input:r})$covmat\n",
    "    train.z = as.matrix(dat$train.z)\n",
    "    rownames(train.z) = NULL\n",
    "    colnames(train.z) = NULL\n",
    "    train.v = train.z/train.z\n",
    "    res = compute.hm.train.log.lik.pen.vmat(train.b=train.z,\n",
    "                                            covmat=covmat,\n",
    "                                            A='.remove_before_rerun', \n",
    "                                            pen=1,\n",
    "                                            train.s=train.v,\n",
    "                                            cormat=v.mat)\n",
    "    saveRDS(res$pis, ${_output[0]:r})\n",
    "    saveRDS(res$lik.mat, ${_output[1]:r})\n",
    "\n",
    "bash:\n",
    "    rm -f *.remove_before_rerun.rds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior inference\n",
    "Applying hyperparameters learned from the training set to the test set, the cell below computes posterior quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "[mash_4]\n",
    "# Posterior inference on the \"top\" set of gene-snp pairs (time estimate: )\n",
    "depends: sos_variable('prior_matrices')\n",
    "output: f\"{_input[0]:nn}.posterior.rds\"\n",
    "R: expand = \"${ }\", workdir = cwd\n",
    "    setwd(${mashr_src:dar})\n",
    "    ret = sapply(list.files(pattern = \"*.R\"), source, .GlobalEnv)\n",
    "    setwd(${cwd:ar})\n",
    "    dat = readRDS(${mash_input[0]:r})\n",
    "    z.stat = dat$test.z\n",
    "    v.mat = dat$vhat\n",
    "    s.j = matrix(rep(1,ncol(z.stat)*nrow(z.stat)),ncol=ncol(z.stat),nrow=nrow(z.stat))\n",
    "    pis = readRDS(${_input[0]:r})$pihat\n",
    "    covmat = readRDS(${prior_matrices:r})$covmat\n",
    "    res = lapply(seq(1:nrow(z.stat)), function(j){\n",
    "        total.quant.per.snp.with.vmat(j=j, covmat=covmat, \n",
    "                                      b.gp.hat=z.stat, \n",
    "                                      cormat=v.mat, \n",
    "                                      se.gp.hat=s.j, \n",
    "                                      pis=pis, \n",
    "                                      A='remove_before_rerun', \n",
    "                                      checkpoint=TRUE)})\n",
    "    # data formatting.\n",
    "    out = do.call(Map, c(f = rbind, res))\n",
    "    saveRDS(out, ${_output:r})\n",
    "\n",
    "bash:\n",
    "    rm -f *.remove_before_rerun.rds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now MASH analysis is complete. I will use a separate notebook to summarize, plot and visualize the result of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and run default pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[export]\n",
    "# Export notebook to HTML file\n",
    "input: [item for item in sys.argv if item.endswith('.ipynb')], group_by = 1, pattern = '{fd}/{fn}.ipynb'\n",
    "output: expand_pattern(f'{cwd:a}/{_fn[0]}.html')\n",
    "bash: expand = True, stderr = False\n",
    "  sos convert {_input} {_output}\n",
    "  \n",
    "[default]\n",
    "sos_run('export+sfa+mash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p class=\"session_section\">SoS</p>\n",
       "<table class=\"session_info\">\n",
       "<tr>\n",
       "<th>SoS Version</th><td><pre>0.9.13.3</pre></td>\n",
       "</tr>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sessioninfo"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
